{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3161a69-6264-44a3-beb8-59813ace7f10",
   "metadata": {},
   "source": [
    "# Versi 1 : 1 Patch untuk 1 Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ab824-4b72-421e-bfc8-8f71e1851365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "# Import semua library dasar yang dibutuhkan\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e21e3-b6ff-441d-be7a-56dc29f83c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "# Encoder 3D: bertugas mengekstraksi fitur spasial dan spektral dari patch hyperspectral.\n",
    "\n",
    "class SpectralSpatialEncoder3D(nn.Module):\n",
    "    def __init__(self, embedding_dim=256, init_channels=32):\n",
    "        super().__init__()\n",
    "        # Lapisan konvolusi pertama: kernel 3x3x20, stride sama (non-overlapping)\n",
    "        self.conv1 = nn.Conv3d(1, init_channels, kernel_size=(3,3,20), stride=(3,3,20), padding=0)\n",
    "        self.bn1 = nn.BatchNorm3d(init_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Lapisan konvolusi kedua: memperkecil spasial menjadi 1x1\n",
    "        self.conv2 = nn.Conv3d(init_channels, init_channels*2, kernel_size=(3,3,1), stride=(3,3,1), padding=0)\n",
    "        self.bn2 = nn.BatchNorm3d(init_channels*2)\n",
    "\n",
    "        # Lapisan fully connected untuk memproyeksikan ke embedding 1D\n",
    "        self.fc = nn.Linear(init_channels*2, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: tensor input\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Pooling agar hasil akhirnya 1 nilai per channel (rata-rata)\n",
    "        x = F.adaptive_avg_pool3d(x, (1,1,1))\n",
    "        x = torch.flatten(x, 1)  # dari (B, C,1,1,1) -> (B,C)\n",
    "        x = self.fc(x)           # ubah ke panjang embedding_dim (misal 256)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17df81-20ac-46ac-b483-2f838a6c265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "# Fungsi ini menambahkan noise Gaussian ke vektor embedding hasil encoder\n",
    "# untuk menghasilkan pasangan positif (positive key)\n",
    "\n",
    "class LatentAugmentor:\n",
    "    def __init__(self, sigma=0.1, device='cpu'):\n",
    "        self.sigma = sigma\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, features):\n",
    "        \"\"\"\n",
    "        features: tensor berukuran (B, D)\n",
    "        menghasilkan augmented_features: (B, D)\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(features, device=features.device) * self.sigma\n",
    "        return features + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb12819-c2b2-4ee8-9163-c109f57de6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "# Transformer Encoder sederhana.\n",
    "# Menerima input dalam bentuk (batch, jumlah_token, dimensi_embedding)\n",
    "# Dalam desain sekarang, jumlah_token = 1 (karena 1 patch = 1 token)\n",
    "\n",
    "class SimpleTransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256, num_heads=8, num_layers=2, mlp_dim=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: tensor (B, T, D)\n",
    "        T = jumlah token (di sini 1)\n",
    "        \"\"\"\n",
    "        return self.transformer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb840827-dff4-4807-bac5-ab7e435f6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "# Projection head memetakan output dari transformer ke dimensi ruang latent\n",
    "# tempat dilakukan perhitungan kesamaan (cosine similarity)\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim=256, proj_dim=128, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # hasil akhir berukuran (B, proj_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6c4e8-4926-484c-90e0-43d2e2a35946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "# Implementasi fungsi loss InfoNCE\n",
    "# Mengukur kemiripan antar pasangan (query, positive key) dalam satu batch\n",
    "\n",
    "def info_nce_loss(q, k, temperature=0.1):\n",
    "    \"\"\"\n",
    "    q: queries (B, D)\n",
    "    k: positive keys (B, D)\n",
    "    \"\"\"\n",
    "    # Normalisasi supaya perbandingan berbasis arah (cosine similarity)\n",
    "    q = F.normalize(q, dim=1)\n",
    "    k = F.normalize(k, dim=1)\n",
    "\n",
    "    # Hitung kesamaan antar semua pasangan dalam batch\n",
    "    logits = torch.matmul(q, k.t()) / temperature\n",
    "    labels = torch.arange(logits.size(0), device=logits.device)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55134022-e474-45b9-8a75-a4b08250b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "# Load dataset hasil preprocessing\n",
    "patch_class0 = np.load(\"patch_class0.npy\")  # kelas non-oil spill\n",
    "patch_class1 = np.load(\"patch_class1.npy\")  # kelas oil spill\n",
    "\n",
    "# Cek ukuran masing-masing dataset\n",
    "print(\"Class 0 shape:\", patch_class0.shape)\n",
    "print(\"Class 1 shape:\", patch_class1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5342401-706d-40b2-8e26-c5e29899a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "# Gabungkan semua patch menjadi satu array\n",
    "X_all = np.concatenate([patch_class0, patch_class1], axis=0)\n",
    "\n",
    "# Buat label\n",
    "y_all = np.concatenate([\n",
    "    np.zeros(len(patch_class0)),  # label 0 untuk class 0\n",
    "    np.ones(len(patch_class1))    # label 1 untuk class 1\n",
    "])\n",
    "\n",
    "print(\"Total samples:\", X_all.shape[0])\n",
    "print(\"Labels shape:\", y_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbbec9-b9c0-4e33-9796-b383514c4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9\n",
    "# Ubah dari numpy ke tensor\n",
    "X_tensor = torch.tensor(X_all, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_all, dtype=torch.long)\n",
    "\n",
    "# Ubah bentuk ke format Conv3D (N, C, D, H, W)\n",
    "X_tensor = X_tensor.unsqueeze(1).permute(0, 1, 4, 2, 3)\n",
    "\n",
    "print(\"Tensor shape setelah permute:\", X_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93933b8-9158-4b4b-9796-e3fc2850d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10\n",
    "# Split train dan validation\n",
    "\n",
    "# Tentukan ukuran train dan validation\n",
    "train_size = int(0.8 * len(X_tensor))\n",
    "val_size = len(X_tensor) - train_size\n",
    "\n",
    "# Buat indeks acak untuk memastikan X dan y sejajar\n",
    "indices = torch.randperm(len(X_tensor))\n",
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:]\n",
    "\n",
    "# Bagi data berdasarkan indeks yang sama\n",
    "train_X = X_tensor[train_idx]\n",
    "train_y = y_tensor[train_idx]\n",
    "val_X = X_tensor[val_idx]\n",
    "val_y = y_tensor[val_idx]\n",
    "\n",
    "# Buat TensorDataset\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "val_dataset = TensorDataset(val_X, val_y)\n",
    "\n",
    "# Buat DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)} | Validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d497c6-f756-48da-b32b-3bfc81555b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11\n",
    "# Inisialisasi perangkat dan model\n",
    "# Inisialisasi perangkat\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Inisialisasi model\n",
    "encoder = SpectralSpatialEncoder3D(embedding_dim=256).to(device)\n",
    "augmentor = LatentAugmentor(sigma=0.08)\n",
    "transformer = SimpleTransformerEncoder(embed_dim=256).to(device)\n",
    "proj_head = ProjectionHead(in_dim=256, proj_dim=128).to(device)\n",
    "\n",
    "# Optimizer\n",
    "params = list(encoder.parameters()) + list(transformer.parameters()) + list(proj_head.parameters())\n",
    "optimizer = optim.AdamW(params, lr=1e-4, weight_decay=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a636d51-5d87-49a0-bc4c-bcc2b9655950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "# Training loop dengan validasi per epoch (dengan checkpoint & resume)\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== PARAMETER ====\n",
    "START_EPOCH = 1          # default, akan ditimpa otomatis jika ada checkpoint\n",
    "NUM_EPOCHS = 20\n",
    "temperature = 0.1\n",
    "best_val_loss = float('inf')\n",
    "checkpoint_path = \"checkpoint_sst_transformer.pt\"\n",
    "\n",
    "# ==== Jika checkpoint ada, lanjutkan dari sana ====\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    encoder.load_state_dict(checkpoint[\"encoder_state\"])\n",
    "    transformer.load_state_dict(checkpoint[\"transformer_state\"])\n",
    "    proj_head.load_state_dict(checkpoint[\"proj_head_state\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    START_EPOCH = checkpoint[\"epoch\"] + 1\n",
    "    best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "    print(f\"[OK] Checkpoint ditemukan. Melanjutkan dari epoch {START_EPOCH}.\")\n",
    "else:\n",
    "    print(\"[MAAF] Tidak ditemukan checkpoint. Memulai training dari awal.\")\n",
    "\n",
    "# ==== Mulai Training ====\n",
    "for epoch in range(START_EPOCH, NUM_EPOCHS+1):  # Start awal di 1, hingga nanti di 21 - 1\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ------------------------\n",
    "    # MODE TRAIN\n",
    "    # ------------------------\n",
    "    encoder.train()\n",
    "    transformer.train()\n",
    "    proj_head.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Train]\", leave=True)\n",
    "    for batch_X, _ in train_bar:\n",
    "        batch_X = batch_X.to(device)\n",
    "\n",
    "        # 1. Encode\n",
    "        features = encoder(batch_X)\n",
    "\n",
    "        # 2. Latent augmentation\n",
    "        aug_features = augmentor(features)\n",
    "\n",
    "        # 3. Transformer + Projection\n",
    "        z_orig = proj_head(transformer(features.unsqueeze(1)))\n",
    "        z_aug  = proj_head(transformer(aug_features.unsqueeze(1)))\n",
    "\n",
    "        # 4. InfoNCE loss\n",
    "        loss = info_nce_loss(z_orig, z_aug, temperature=temperature)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # ------------------------\n",
    "    # MODE VALIDASI\n",
    "    # ------------------------\n",
    "    encoder.eval()\n",
    "    transformer.eval()\n",
    "    proj_head.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Val]\", leave=True)\n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in val_bar:\n",
    "            batch_X = batch_X.to(device)\n",
    "            features = encoder(batch_X)\n",
    "            aug_features = augmentor(features)\n",
    "            z_orig = proj_head(transformer(features.unsqueeze(1)))\n",
    "            z_aug  = proj_head(transformer(aug_features.unsqueeze(1)))\n",
    "            loss = info_nce_loss(z_orig, z_aug, temperature=temperature)\n",
    "            total_val_loss += loss.item()\n",
    "            val_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{NUM_EPOCHS}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "          f\"Time: {elapsed:.2f}s\")\n",
    "\n",
    "    # ------------------------\n",
    "    # SIMPAN CHECKPOINT (checkpoint memiliki file-nya sendiri)\n",
    "    # ------------------------\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"encoder_state\": encoder.state_dict(),\n",
    "        \"transformer_state\": transformer.state_dict(),\n",
    "        \"proj_head_state\": proj_head.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "    # Simpan model terbaik (model terbaik memiliki file-nya sendiri)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(checkpoint, \"best_sst_transformer.pt\")\n",
    "        print(\"OK Model terbaik disimpan.\")\n",
    "\n",
    "print(\"Alhamdulillah, Training selesai.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
